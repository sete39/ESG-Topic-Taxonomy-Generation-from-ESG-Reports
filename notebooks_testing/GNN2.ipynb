{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from spektral.data import BatchLoader, DisjointLoader\n",
    "from spektral.datasets import TUDataset\n",
    "from spektral.layers import GCNConv, GlobalAvgPool, GraphMasking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saif8\\miniconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded PROTEINS.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saif8\\miniconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saif8\\AppData\\Local\\Temp\\ipykernel_21556\\3797974380.py:18: UserWarning: you are shuffling a 'TUDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(data)\n"
     ]
    }
   ],
   "source": [
    "# physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "# if len(physical_devices) > 0:\n",
    "#     tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "################################################################################\n",
    "# Config\n",
    "################################################################################\n",
    "learning_rate = 1e-3  # Learning rate\n",
    "epochs = 10  # Number of training epochs\n",
    "batch_size = 32  # Batch size\n",
    "\n",
    "################################################################################\n",
    "# Load data\n",
    "################################################################################\n",
    "data = TUDataset(\"PROTEINS\")\n",
    "\n",
    "# Train/test split\n",
    "np.random.shuffle(data)\n",
    "split = int(0.8 * len(data))\n",
    "data_tr, data_te = data[:split], data[split:]\n",
    "\n",
    "F = data.n_node_features  # Dimension of node features\n",
    "S = data.n_edge_features  # Dimension of edge features\n",
    "n_out = data.n_labels  # Dimension of the target\n",
    "# Data loaders\n",
    "loader_tr = DisjointLoader(data_tr, batch_size=batch_size, epochs=epochs)\n",
    "loader_te = DisjointLoader(data_te, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Build model\n",
    "################################################################################\n",
    "class Net(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(32, activation=\"relu\")\n",
    "        self.conv2 = GCNConv(32, activation=\"relu\")\n",
    "        self.global_pool = GlobalAvgPool()\n",
    "        self.dense = Dense(n_out)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, a, i = inputs\n",
    "        print(x, a, i)\n",
    "        x = self.conv1([x, a])\n",
    "        x = self.conv2([x, a])\n",
    "        output = self.global_pool([x, i])\n",
    "        output = self.dense(output)\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "optimizer = Adam(learning_rate)\n",
    "model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Tensor(\"net_2/Cast:0\", shape=(None, 4), dtype=float32) SparseTensor(indices=Tensor(\"DeserializeSparse:0\", shape=(None, 2), dtype=int64), values=Tensor(\"net_2/Cast_1:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"DeserializeSparse:2\", shape=(2,), dtype=int64)) Tensor(\"IteratorGetNext:2\", shape=(None,), dtype=int64)\n",
      "Tensor(\"net_2/Cast:0\", shape=(None, 4), dtype=float32) SparseTensor(indices=Tensor(\"DeserializeSparse:0\", shape=(None, 2), dtype=int64), values=Tensor(\"net_2/Cast_1:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"DeserializeSparse:2\", shape=(2,), dtype=int64)) Tensor(\"IteratorGetNext:2\", shape=(None,), dtype=int64)\n",
      " 9/28 [========>.....................] - ETA: 0s - loss: 9.3463 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saif8\\miniconda3\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'TUDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 2s 23ms/step - loss: 9.2905\n",
      "Epoch 2/10\n",
      "28/28 [==============================] - 1s 23ms/step - loss: 9.2905\n",
      "Epoch 3/10\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 9.2905\n",
      "Epoch 4/10\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 9.2905\n",
      "Epoch 5/10\n",
      "28/28 [==============================] - 1s 22ms/step - loss: 9.2905\n",
      "Epoch 6/10\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 9.2905\n",
      "Epoch 7/10\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 9.2905\n",
      "Epoch 8/10\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 9.2905\n",
      "Epoch 9/10\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 9.2905\n",
      "Epoch 10/10\n",
      " 8/28 [=======>......................] - ETA: 0s - loss: 9.2553"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Fit model\n",
    "################################################################################\n",
    "model.fit(loader_tr.load(), steps_per_epoch=loader_tr.steps_per_epoch, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"net\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gcn_conv (GCNConv)          multiple                  160       \n",
      "                                                                 \n",
      " gcn_conv_1 (GCNConv)        multiple                  1056      \n",
      "                                                                 \n",
      " global_avg_pool (GlobalAvgP  multiple                 0         \n",
      " ool)                                                            \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,282\n",
      "Trainable params: 1,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.6660\n",
      "Done. Test loss: 0.6660286784172058\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Evaluate model\n",
    "################################################################################\n",
    "print(\"Testing model\")\n",
    "loss = model.evaluate(loader_te.load(), steps=loader_te.steps_per_epoch)\n",
    "print(\"Done. Test loss: {}\".format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((TensorSpec(shape=(None, 4), dtype=tf.float64, name=None),\n",
       "  SparseTensorSpec(TensorShape([None, None]), tf.float64),\n",
       "  TensorSpec(shape=(None,), dtype=tf.int64, name=None)),\n",
       " TensorSpec(shape=(None, 2), dtype=tf.float64, name=None))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader_tr.tf_signature()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(n_nodes=79, n_node_features=4, n_edge_features=None, n_labels=2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "a = tf.random.normal((1, 3)) # shape = (batch, embedding_1_dim)\n",
    "b = tf.random.normal((5, 3, 7)) # shape = (output_dim, embedding_1_dim, embedding_2_dim)\n",
    "c = tf.random.normal((1, 7)) # shape = (batch, embedding_2_dim)\n",
    "bi = tf.einsum('ik,jkl,il->ij', a, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       "array([[-0.39689445, -1.0620351 ,  6.173465  , -8.726854  , -7.693402  ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
