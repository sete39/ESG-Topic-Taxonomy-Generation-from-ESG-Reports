{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading df\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../dataset/DBPEDIA_train.csv')\n",
    "document_list = df['text'].to_numpy().astype('str')\n",
    "document_list.dtype\n",
    "print('Finished reading df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding topics to create the adjacency matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "labelEncoder = LabelEncoder()\n",
    "topics = np.concatenate((df['l1'].unique(), df['l2'].unique(), df['l3'].unique()))\n",
    "# For virtual node when expanding topic taxonomy\n",
    "topics = np.append(topics, 'ZZ_VIRTUAL')\n",
    "labelEncoder.fit(topics)\n",
    "\n",
    "def encode_topic(topic):\n",
    "    print(type(topic))\n",
    "    return labelEncoder.transform(topic)\n",
    "\n",
    "df['l1_encoded'] = labelEncoder.transform(df['l1'])\n",
    "df['l2_encoded'] = labelEncoder.transform(df['l2'])\n",
    "df['l3_encoded'] = labelEncoder.transform(df['l3'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-03 17:41:07.951364: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-03 17:41:08.079157: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-03 17:41:08.612364: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /software/spackages_prod/apps/linux-ubuntu20.04-zen2/gcc-9.4.0/cudnn-8.2.4.15-11.4-aa4jklovfx75n2q4jcbyc3dgemu5nqpu/lib64:/software/spackages_prod/apps/linux-ubuntu20.04-zen2/gcc-9.4.0/cuda-11.4.2-sg5bamqhm7bmiz3nf43yzo5thibytq7t/lib64:/software/spackages_prod/apps/linux-ubuntu20.04-zen2/gcc-9.4.0/libxml2-2.9.12-i7nsnmeeeukas6sc2rqa6adykxtky4yj/lib:/software/spackages_prod/apps/linux-ubuntu20.04-zen2/gcc-9.4.0/xz-5.2.5-wfweai2jkkplgry3aqkfb5fqg44fuxtf/lib:/software/spackages_prod/apps/linux-ubuntu20.04-zen2/gcc-9.4.0/libiconv-1.16-xa6oobihv7qsbf743iq5g3ioyriyjxwj/lib:/software/spackages_prod/apps/linux-ubuntu20.04-zen2/gcc-9.4.0/zlib-1.2.11-un5j7szis72ayqdk4yzjlp6vkjrcbtn7/lib:/software/spackages_prod/apps/linux-ubuntu20.04-zen2/gcc-9.4.0/openssl-1.1.1l-fw26x5iyyvh4yqpxd6eq7jdnu2kydwkm/lib\n",
      "2023-04-03 17:41:08.612439: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /software/spackages_prod/apps/linux-ubuntu20.04-zen2/gcc-9.4.0/cudnn-8.2.4.15-11.4-aa4jklovfx75n2q4jcbyc3dgemu5nqpu/lib64:/software/spackages_prod/apps/linux-ubuntu20.04-zen2/gcc-9.4.0/cuda-11.4.2-sg5bamqhm7bmiz3nf43yzo5thibytq7t/lib64:/software/spackages_prod/apps/linux-ubuntu20.04-zen2/gcc-9.4.0/libxml2-2.9.12-i7nsnmeeeukas6sc2rqa6adykxtky4yj/lib:/software/spackages_prod/apps/linux-ubuntu20.04-zen2/gcc-9.4.0/xz-5.2.5-wfweai2jkkplgry3aqkfb5fqg44fuxtf/lib:/software/spackages_prod/apps/linux-ubuntu20.04-zen2/gcc-9.4.0/libiconv-1.16-xa6oobihv7qsbf743iq5g3ioyriyjxwj/lib:/software/spackages_prod/apps/linux-ubuntu20.04-zen2/gcc-9.4.0/zlib-1.2.11-un5j7szis72ayqdk4yzjlp6vkjrcbtn7/lib:/software/spackages_prod/apps/linux-ubuntu20.04-zen2/gcc-9.4.0/openssl-1.1.1l-fw26x5iyyvh4yqpxd6eq7jdnu2kydwkm/lib\n",
      "2023-04-03 17:41:08.612444: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "max_len = 512\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "encoded_topic_to_tokenized_dict = {}\n",
    "for topic in topics:\n",
    "    # dbpedia categories are in PascalCase, so this makes them spaced\n",
    "    spaced_words = re.sub( r\"([A-Z])\", r\" \\1\", topic)[1:]\n",
    "    tokenized_sequence = tokenizer.encode_plus(spaced_words, add_special_tokens=True, max_length=max_len, padding='max_length')['input_ids']\n",
    "\n",
    "    encoded_topic_to_tokenized_dict[labelEncoder.transform([topic])[0]] = tokenized_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# documents = df['text'].apply(lambda doc: np.array(tokenizer.encode_plus(doc, add_special_tokens=True, max_length=max_len, padding='max_length', truncation=True)['input_ids'])).to_numpy()\n",
    "# documents_labels = labelEncoder.transform(df['l3'].to_numpy())\n",
    "# documents_fixed = np.empty(shape=(len(documents), max_len))\n",
    "# for i, doc in enumerate(documents):\n",
    "#     documents_fixed[i] = doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open(\"tokenized_dbpedia.pkl\", \"wb\") as f:\n",
    "#     pickle.dump([documents_fixed, documents_labels], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished getting tokenized file\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with (open(\"./tokenized_dbpedia.pkl\", \"rb\")) as f:\n",
    "    documents, documents_labels = pickle.load(f)\n",
    "print('Finished getting tokenized file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_dict = {}\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    l1 = row['l1_encoded']\n",
    "    l2 = row['l2_encoded']\n",
    "    l3 = row['l3_encoded']\n",
    "\n",
    "    if l1 not in graph_dict:\n",
    "        graph_dict[l1] = {}\n",
    "    if l2 not in graph_dict[l1]:\n",
    "        graph_dict[l1][l2] = {} \n",
    "\n",
    "    graph_dict[l1][l2][l3] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating node features\n",
    "x = np.arange(298)\n",
    "x = labelEncoder.inverse_transform(x)\n",
    "feature_array = x.reshape(298, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished getting GlOVE embedder\n"
     ]
    }
   ],
   "source": [
    "# loading GloVe model to get topic word embeddings\n",
    "# from https://stackoverflow.com/questions/37793118/load-pretrained-glove-vectors-in-python\n",
    "import torchtext\n",
    "\n",
    "glove = torchtext.vocab.GloVe(name=\"6B\", dim=50)\n",
    "print('Finished getting GlOVE embedder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove['MASK'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating \"ego-graphs\" (each node is seperated into a graph with itself, parent, and siblings)\n",
    "# The base node (so the node itself) will be masked, aka. have a [MASK] embedding\n",
    "# The sibling nodes need to have a negative relationship with the base node (so negative value in adjacency matrix?)\n",
    "from spektral.data import Graph\n",
    "import numpy as np\n",
    "import re\n",
    "def create_ego_graph(l1_topic, l2_topic, l3_topic, graph_dict):\n",
    "    if l3_topic != None:\n",
    "        siblings_list = list(graph_dict[l1_topic][l2_topic].keys())\n",
    "        siblings_list.remove(l3_topic)\n",
    "        base = l3_topic\n",
    "        parent = l2_topic\n",
    "        grandparent = l1_topic\n",
    "\n",
    "        all_nodes_list = siblings_list.copy()\n",
    "        all_nodes_list.append(base)\n",
    "        all_nodes_list.append(parent)\n",
    "        all_nodes_list.append(grandparent)\n",
    "        \n",
    "        n_nodes = len(all_nodes_list)\n",
    "        adj_matrix = np.zeros((n_nodes, n_nodes))\n",
    "\n",
    "        node_label_encoder = LabelEncoder()\n",
    "        node_label_encoder.fit(all_nodes_list)\n",
    "        \n",
    "        encoded_base = node_label_encoder.transform([base])[0]\n",
    "        encoded_parent = node_label_encoder.transform([parent])[0]\n",
    "        encoded_grandparent = node_label_encoder.transform([grandparent])[0]\n",
    "\n",
    "        adj_matrix[encoded_base][encoded_parent] = 1\n",
    "        adj_matrix[encoded_parent][encoded_base] = 1\n",
    "\n",
    "        adj_matrix[encoded_grandparent][encoded_parent] = 1\n",
    "        adj_matrix[encoded_parent][encoded_grandparent] = 1\n",
    "\n",
    "        for sibling in siblings_list: \n",
    "            encoded_sibling = node_label_encoder.transform([sibling])[0]\n",
    "            adj_matrix[encoded_sibling][encoded_base] = -1\n",
    "            adj_matrix[encoded_base][encoded_sibling] = -1\n",
    "        \n",
    "    elif l2_topic != None:\n",
    "        siblings_list = list(graph_dict[l1_topic].keys())\n",
    "        siblings_list.remove(l2_topic)\n",
    "        base = l2_topic\n",
    "        parent = l1_topic\n",
    "\n",
    "        all_nodes_list = siblings_list.copy()\n",
    "        all_nodes_list.append(base)\n",
    "        all_nodes_list.append(parent)\n",
    "        \n",
    "        n_nodes = len(all_nodes_list)\n",
    "        adj_matrix = np.zeros((n_nodes, n_nodes))\n",
    "\n",
    "        node_label_encoder = LabelEncoder()\n",
    "        node_label_encoder.fit(all_nodes_list)\n",
    "        \n",
    "        encoded_base = node_label_encoder.transform([base])[0]\n",
    "        encoded_parent = node_label_encoder.transform([parent])[0]\n",
    "\n",
    "        adj_matrix[encoded_base][encoded_parent] = 1\n",
    "        adj_matrix[encoded_parent][encoded_base] = 1\n",
    "\n",
    "        for sibling in siblings_list: \n",
    "            encoded_sibling = node_label_encoder.transform([sibling])[0]\n",
    "            adj_matrix[encoded_sibling][encoded_base] = -1\n",
    "            adj_matrix[encoded_base][encoded_sibling] = -1\n",
    "    \n",
    "    elif l1_topic != None:\n",
    "        siblings_list = list(graph_dict.keys())\n",
    "        siblings_list.remove(l1_topic)\n",
    "        base = l1_topic\n",
    "\n",
    "        all_nodes_list = siblings_list.copy()\n",
    "        all_nodes_list.append(base)\n",
    "        \n",
    "        n_nodes = len(all_nodes_list)\n",
    "        adj_matrix = np.zeros((n_nodes, n_nodes))\n",
    "\n",
    "        node_label_encoder = LabelEncoder()\n",
    "        node_label_encoder.fit(all_nodes_list)\n",
    "        \n",
    "        encoded_base = node_label_encoder.transform([base])[0]\n",
    "\n",
    "        for sibling in siblings_list: \n",
    "            encoded_sibling = node_label_encoder.transform([sibling])[0]\n",
    "            adj_matrix[encoded_sibling][encoded_base] = -1\n",
    "            adj_matrix[encoded_base][encoded_sibling] = -1\n",
    "\n",
    "    ego_features = np.zeros((n_nodes, 50))\n",
    "    encoded_nodes_list = node_label_encoder.transform(all_nodes_list)\n",
    "\n",
    "    for i, node in enumerate(all_nodes_list):\n",
    "        feature = feature_array[node]\n",
    "        split_words_list = re.sub( r\"([A-Z])\", r\" \\1\", feature[0]).split()\n",
    "        n_words = len(split_words_list)\n",
    "        embedding_avg = np.array([glove[word.lower()].numpy() for word in split_words_list]).sum(axis=0)/n_words\n",
    "        \n",
    "        # Masking base node, setting the embedding to all 0's\n",
    "        if (node == base):\n",
    "            embedding_avg = glove['MASK']\n",
    "\n",
    "        ego_features[encoded_nodes_list[i]] = embedding_avg\n",
    "\n",
    "    return Graph(a=adj_matrix, x=ego_features, y=(l1_topic, l2_topic, l3_topic))\n",
    "\n",
    "graph_list = []\n",
    "\n",
    "for l1_topic in graph_dict:\n",
    "    for l2_topic in graph_dict[l1_topic]:\n",
    "        for l3_topic in graph_dict[l1_topic][l2_topic]:\n",
    "            graph_list.append(create_ego_graph(l1_topic, l2_topic, l3_topic, graph_dict))\n",
    "        graph_list.append(create_ego_graph(l1_topic, l2_topic, None, graph_dict))\n",
    "    graph_list.append(create_ego_graph(l1_topic, None, None, graph_dict))\n",
    "\n",
    "graph_list = np.array(graph_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spektral.data import Dataset\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self, graph_list: list[Graph], **kwargs):\n",
    "        self.graph_list = graph_list\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def read(self):\n",
    "        # We must return a list of Graph objects\n",
    "        num_l =  np.random.permutation(len(self.graph_list))\n",
    "        return [self.graph_list[i] for i in num_l]\n",
    "    \n",
    "dataset = MyDataset(graph_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers.Bilinear import Bilinear\n",
    "from layers.ContextEmbedding import ContextEmbedding\n",
    "from layers.TopicAttentiveEmbedding import TopicAttentiveEmbedding\n",
    "\n",
    "from utils.TopicExpanTrainGen import TopicExpanTrainGen\n",
    "\n",
    "def sequence_to_document_embedding(sequence_embedding: tf.Tensor):\n",
    "    # gets the document representation/embedding from a BERT sequence embedding\n",
    "    # by getting the mean-pooling of the sequence \n",
    "    return tf.math.reduce_mean(sequence_embedding, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-03 17:41:28.226714: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-03 17:41:29.619830: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38220 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:31:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import int64\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input, Lambda\n",
    "from spektral.layers import GCNConv, GlobalAvgPool\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import categorical_accuracy\n",
    "import tensorflow as tf\n",
    "from transformers import TFBertModel\n",
    "import keras_nlp\n",
    "\n",
    "learning_rate = 5e-5  # Learning rate\n",
    "epochs = 4  # Number of training epochs\n",
    "batch_size = 32  # Batch size\n",
    "weight_decay = 5e-6\n",
    "mini_batch_size = 4 # a mini-batch will always have 1 positive triple, and (n-1) negative triples\n",
    "                    # i.e. with a mini_batch_size of 4, we have 1 pos. doc. and 3 neg. docs.\n",
    "batch_ratio = int(batch_size / mini_batch_size)\n",
    "\n",
    "max_len = 512\n",
    "vocab_size = tokenizer.vocab_size\n",
    "infoNCE_temprature = 0.1\n",
    "\n",
    "optimizer = Adam(learning_rate, weight_decay=weight_decay)\n",
    "loss_fn = SparseCategoricalCrossentropy(from_logits=True)\n",
    "loss_fn_binary = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "loss_fn_crossentropy = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "n_out = dataset.n_labels\n",
    "topic_embedding_dimension = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Custom training loop\n",
    "class ModelWithNCE(Model):\n",
    "    @tf.function(experimental_relax_shapes=True)\n",
    "    def train_step(self, data):\n",
    "        inputs, target = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            similarity_prediction, phrase_prediction = self(inputs, training=True)\n",
    "            similarity_prediction_infonce = tf.reshape(similarity_prediction / infoNCE_temprature, shape=(mini_batch_size, -1))\n",
    "\n",
    "            # infoNCE_loss = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(labels=tf.reshape(target[0], shape=(mini_batch_size, -1)), logits=similarity_prediction_infonce))\n",
    "            # infoNCE_loss = loss_fn_crossentropy(tf.reshape(target[0], shape=(mini_batch_size, -1)), similarity_prediction_infonce)\n",
    "            bce_loss = loss_fn_binary(target[0], similarity_prediction)\n",
    "            phrase_loss = loss_fn(target[1], phrase_prediction)\n",
    "\n",
    "            # tf.print(similarity_prediction[:4], bce_loss, phrase_loss, output_stream=sys.stderr)\n",
    "        gradients = tape.gradient([bce_loss, phrase_loss], self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        self.compiled_metrics.update_state(target, (similarity_prediction, phrase_prediction))\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic_expan_generator = TopicExpanTrainGen(graph_list, documents, documents_labels, batch_size, mini_batch_size, encoded_topic_to_tokenized_dict)\n",
    "#, arr = topic_expan_generator.__getitem__(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# arr[1][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-03 17:41:33.100081: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /users/k21148846/.conda/envs/esg/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "shared_bilinear = Bilinear(topic_embedding_dimension, 768, 1)\n",
    "\n",
    "# GNNs (Topic Encoder)\n",
    "X_in = Input(shape=(dataset.n_node_features))\n",
    "A_in = Input(shape=(None,), sparse=True)\n",
    "I_in = Input(shape=(), dtype=int64)\n",
    "\n",
    "topic_embedding = GCNConv(topic_embedding_dimension, activation='relu')([X_in, A_in])\n",
    "topic_embedding = GCNConv(topic_embedding_dimension, activation='relu')([topic_embedding, A_in])\n",
    "topic_embedding = GlobalAvgPool(name='topic_embedding')([topic_embedding, I_in])\n",
    "\n",
    "# BERT Embedding (Document Encoder)\n",
    "max_seq_length = max_len\n",
    "encoder = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "input_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_ids\")\n",
    "embedding = encoder(input_ids)[0]\n",
    "\n",
    "# Transformer Decoders (Phrase Generator)\n",
    "decoder_tokens_input = Input(shape=(max_len,), name=\"decoder_phrase_input\")\n",
    "decoder_embedding = keras_nlp.layers.TokenAndPositionEmbedding(vocabulary_size=vocab_size, sequence_length=max_len, embedding_dim=768, mask_zero=True)(decoder_tokens_input)\n",
    "\n",
    "# Getting context embedding for decoder\n",
    "topic_attentive_embedding = TopicAttentiveEmbedding()(topic_embedding, embedding, shared_bilinear, training=False)\n",
    "topic_attentive_embedding = tf.keras.layers.Reshape((max_len, 1))(topic_attentive_embedding)\n",
    "context_embedding = ContextEmbedding()([topic_attentive_embedding, embedding])\n",
    "\n",
    "transformer_decoder = keras_nlp.layers.TransformerDecoder(\n",
    "    num_heads=16, \n",
    "    intermediate_dim=max_len,\n",
    "    dropout=0.1\n",
    ")(decoder_embedding, context_embedding)\n",
    "\n",
    "# Transformer Output\n",
    "out2 = Dense(vocab_size)(transformer_decoder)\n",
    "\n",
    "# Output Bilinear layer (Similarity Predictor)\n",
    "document_embedding = Lambda(sequence_to_document_embedding, name='document_embedding')(embedding)\n",
    "out = shared_bilinear([topic_embedding, document_embedding])\n",
    "\n",
    "# Outputs\n",
    "model = ModelWithNCE(inputs=[X_in, A_in, I_in, input_ids, decoder_tokens_input], outputs=[out, out2])\n",
    "\n",
    "# compiling model and adding metrics\n",
    "perplexity = keras_nlp.metrics.Perplexity(from_logits=True, mask_token_id=0)\n",
    "model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy', perplexity], run_eagerly=True)\n",
    "\n",
    "topic_expan_generator = TopicExpanTrainGen(graph_list, documents[:-20000], documents_labels[:-20000], batch_size, mini_batch_size, encoded_topic_to_tokenized_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_with_nce\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 50)]         0           []                               \n",
      "                                                                                                  \n",
      " input_5 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " gcn_conv_2 (GCNConv)           (None, 300)          15300       ['input_4[0][0]',                \n",
      "                                                                  'input_5[0][0]']                \n",
      "                                                                                                  \n",
      " gcn_conv_3 (GCNConv)           (None, 300)          90300       ['gcn_conv_2[0][0]',             \n",
      "                                                                  'input_5[0][0]']                \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " input_ids (InputLayer)         [(None, 512)]        0           []                               \n",
      "                                                                                                  \n",
      " topic_embedding (GlobalAvgPool  (None, 300)         0           ['gcn_conv_3[0][0]',             \n",
      " )                                                                'input_6[0][0]']                \n",
      "                                                                                                  \n",
      " tf_bert_model_1 (TFBertModel)  TFBaseModelOutputWi  109482240   ['input_ids[0][0]']              \n",
      "                                thPoolingAndCrossAt                                               \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, 512,                                               \n",
      "                                 768),                                                            \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " topic_attentive_embedding_1 (T  (None, 512)         0           ['topic_embedding[0][0]',        \n",
      " opicAttentiveEmbedding)                                          'tf_bert_model_1[0][0]']        \n",
      "                                                                                                  \n",
      " decoder_phrase_input (InputLay  [(None, 512)]       0           []                               \n",
      " er)                                                                                              \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 512, 1)       0           ['topic_attentive_embedding_1[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " token_and_position_embedding_1  (None, 512, 768)    23834112    ['decoder_phrase_input[0][0]']   \n",
      "  (TokenAndPositionEmbedding)                                                                     \n",
      "                                                                                                  \n",
      " context_embedding_1 (ContextEm  (None, 512, 768)    0           ['reshape_1[0][0]',              \n",
      " bedding)                                                         'tf_bert_model_1[0][0]']        \n",
      "                                                                                                  \n",
      " document_embedding (Lambda)    (None, 768)          0           ['tf_bert_model_1[0][0]']        \n",
      "                                                                                                  \n",
      " transformer_decoder_1 (Transfo  (None, 512, 768)    5517056     ['token_and_position_embedding_1[\n",
      " rmerDecoder)                                                    0][0]',                          \n",
      "                                                                  'context_embedding_1[0][0]']    \n",
      "                                                                                                  \n",
      " bilinear_1 (Bilinear)          (None, 1)            230401      ['topic_embedding[0][0]',        \n",
      "                                                                  'document_embedding[0][0]']     \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 512, 30522)   23471418    ['transformer_decoder_1[0][0]']  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 162,640,827\n",
      "Trainable params: 162,640,827\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.keras import TqdmCallback\n",
    "\n",
    "# NOTE: Ignore warning about gradients not existing for BERT's dense layer since \n",
    "# the dense layers are not used and are thus unconnected and do not need training\n",
    "\n",
    "checkpoint_filepath = './checkpoint.h5'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor='dense_perplexity',\n",
    "    save_weights_only=True,\n",
    "    save_freq=1000,\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "\n",
    "model.fit(topic_expan_generator, batch_size=batch_size, epochs=epochs, verbose=1, callbacks=[TqdmCallback(verbose=1), model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('checkpoint_april1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = TopicExpanTrainGen(graph_list, documents[-1000:], documents_labels[-1000:], batch_size, 2, encoded_topic_to_tokenized_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 18s 290ms/step - loss: nan - bilinear_1_loss: nan - dense_loss: 0.1204 - bilinear_1_accuracy: 0.9876 - bilinear_1_perplexity: nan - dense_accuracy: 0.9820 - dense_perplexity: 1.1279\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[nan,\n",
       " nan,\n",
       " 0.12036581337451935,\n",
       " 0.9875991940498352,\n",
       " nan,\n",
       " 0.9819642901420593,\n",
       " 1.1279094219207764]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from spektral.data.utils import to_disjoint\n",
    "import tensorflow as tf\n",
    "\n",
    "class TopicExpanExpansionGen(tf.keras.utils.Sequence):\n",
    "    def __init__(self, virtual_graph: Graph, documents: np.array, batch_size: int):\n",
    "        self._virtual_graph = virtual_graph # ego-graph of the new virtual node\n",
    "        self.documents = documents\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # generating initial prompt with the start ID, this is the same prompt\n",
    "        # for all batches since the initial prompt is always [101]\n",
    "        unpadded_prompt = tf.fill((batch_size, 1), 101)\n",
    "        self.initial_prompt = tf.pad(prompt, [[0, 0], [0, max_len-tf.shape(prompt)[1]]])\n",
    "        \n",
    "        # the same virtual node ego-graph is used for the whole batch,\n",
    "        # so generating it in the init to speed up computation\n",
    "        self.x_in, self.a_in, self.i_in = to_disjoint(\n",
    "            x_list=[self._virtual_graph.x for _ in range(batch_size)],\n",
    "            a_list=[self._virtual_graph.a for _ in range(batch_size)]\n",
    "        )\n",
    "        \n",
    "        self.x_in = tf.convert_to_tensor(self.x_in)\n",
    "        self.a_in = tf.convert_to_tensor(self.a_in)\n",
    "        self.i_in = tf.convert_to_tensor(self.i_in)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.documents) / (self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, non_batch_index: int):\n",
    "        idx = non_batch_index * batch_to_mini_batch_ratio\n",
    "        idx_limiter = min(idx + self.batch_size, len(self.x)) # for limiting batch size at end of list\n",
    "        fixed_batch_size = idx_limiter - idx # gets the fixed batch size in case this is the last batch\n",
    "        \n",
    "        model_expansion_inputs = (\n",
    "            self.x_in[:fixed_batch_size],\n",
    "            self.a_in[:fixed_batch_size],\n",
    "            self.i_in[:fixed_batch_size],\n",
    "            tf.convert_to_tensor(self.documents[idx:idx_limiter]),\n",
    "            self.initial_prompt[:fixed_batch_size]\n",
    "        )\n",
    "            \n",
    "        return model_expansion_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y should be a 1d array, got an array of shape () instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[149], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m labelEncoder\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(labelEncoder\u001b[38;5;241m.\u001b[39mclasses_, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvirtual\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mlabelEncoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvirtual\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/esg/lib/python3.9/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/.conda/envs/esg/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:134\u001b[0m, in \u001b[0;36mLabelEncoder.transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;124;03m\"\"\"Transform labels to normalized encoding.\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m    Labels as normalized encodings.\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    133\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 134\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mcolumn_or_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# transform of empty array is empty array\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _num_samples(y) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/esg/lib/python3.9/site-packages/sklearn/utils/validation.py:1202\u001b[0m, in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, dtype, warn)\u001b[0m\n\u001b[1;32m   1193\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1194\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA column-vector y was passed when a 1d array was\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1195\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m expected. Please change the shape of y to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1198\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m   1199\u001b[0m         )\n\u001b[1;32m   1200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _asarray_with_order(xp\u001b[38;5;241m.\u001b[39mreshape(y, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[0;32m-> 1202\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1203\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my should be a 1d array, got an array of shape \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(shape)\n\u001b[1;32m   1204\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: y should be a 1d array, got an array of shape () instead."
     ]
    }
   ],
   "source": [
    "labelEncoder.classes_ = np.append(labelEncoder.classes_, \"virtual\")\n",
    "labelEncoder.transform('virtual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, x2, x3, x4, x5 = test_gen.__getitem__(2)[0]\n",
    "# model(test_gen.__getitem__(2)[0])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = TopicExpanTrainGen(graph_list, documents[-1000:], documents_labels[-1000:], 1, 1, encoded_topic_to_tokenized_dict)\n",
    "x1, x2, x3, x4, x5 = test_gen.__getitem__(3)[0]\n",
    "sequence = x5.numpy()\n",
    "sequence[:, 1:] = 0\n",
    "# sequence[:, 1] = 2447"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 30522), dtype=float32, numpy=\n",
       "array([[-7.874007, -8.135588, -8.380221, ..., -8.34035 , -8.491272,\n",
       "        -8.455162]], dtype=float32)>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model((x1, x2, x3, x4, sequence))[1]\n",
    "pred[:, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=3539>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.argmax(pred[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (2185693414.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[119], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    model(x1, x2, x3, x4,\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "model(x1, x2, x3, x4, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'prime'"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([3539])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]',\n",
       " '[CLS] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]',\n",
       " '[CLS] an [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]',\n",
       " '[CLS] tournament [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]']"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras_nlp.utils import beam_search\n",
    "from random import randint\n",
    "\n",
    "test_batch_size = 4\n",
    "test_gen = TopicExpanTrainGen(graph_list, documents[-20000:], documents_labels[-20000:], test_batch_size, 1, encoded_topic_to_tokenized_dict)\n",
    "x1, x2, x3, x4, x5 = test_gen[randint(0, 4000)][0]\n",
    "\n",
    "START_ID = 101\n",
    "END_ID = 102\n",
    "\n",
    "def token_probability_fn(inputs):\n",
    "    padded_inputs = tf.pad(inputs, [[0, 0], [0, max_len-tf.shape(inputs)[1]]])\n",
    "    repeats = int(padded_inputs.shape[0] / test_batch_size)\n",
    "    # print(inputs.shape)\n",
    "    preds = [\n",
    "        model((\n",
    "            x1, \n",
    "            x2, \n",
    "            x3, \n",
    "            x4, \n",
    "            padded_inputs[repeat_idx*test_batch_size:(repeat_idx+1)*test_batch_size]\n",
    "        ))[1] for repeat_idx in range(repeats)]\n",
    "    \n",
    "    # print(preds)\n",
    "    concatenated_preds = tf.concat(preds, axis=0)\n",
    "    # print(concatenated_preds[:, 0, :].shape)\n",
    "    \n",
    "    # the first zero index is the position in the sequence we're trying to find to add to the sequence\n",
    "    first_zero_index = (padded_inputs.numpy()[0]==0).argmax(axis=0)\n",
    "    return concatenated_preds[:, first_zero_index, :]\n",
    "\n",
    "prompt = tf.fill((test_batch_size, 1), START_ID)\n",
    "\n",
    "predicted_phrases = keras_nlp.utils.beam_search(\n",
    "    token_probability_fn,\n",
    "    prompt,\n",
    "    max_length=10,\n",
    "    num_beams=3,\n",
    "    end_token_id=END_ID,\n",
    "    from_logits=True\n",
    ")\n",
    "[tokenizer.decode(phrase) for phrase in predicted_phrases]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 512), dtype=int32, numpy=\n",
       "array([[101,   0,   0, ...,   0,   0,   0],\n",
       "       [101,   0,   0, ...,   0,   0,   0],\n",
       "       [101,   0,   0, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [101,   0,   0, ...,   0,   0,   0],\n",
       "       [101,   0,   0, ...,   0,   0,   0],\n",
       "       [101,   0,   0, ...,   0,   0,   0]], dtype=int32)>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = tf.fill((batch_size, 1), START_ID)\n",
    "padded_prompt = tf.pad(prompt, [[0, 0], [0, max_len-tf.shape(prompt)[1]]])\n",
    "padded_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-03 18:51:23.138063: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at einsum_op_impl.h:498 : INVALID_ARGUMENT: Expected dimension 4 at axis 0 of the input shaped [32,1,16,48] but got dimension 32\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Exception encountered when calling layer 'multi_head_attention_1' (type MultiHeadAttention).\n\n{{function_node __wrapped__Einsum_N_2_device_/job:localhost/replica:0/task:0/device:GPU:0}} Expected dimension 4 at axis 0 of the input shaped [32,1,16,48] but got dimension 32 [Op:Einsum]\n\nCall arguments received by layer 'multi_head_attention_1' (type MultiHeadAttention):\n  • query=tf.Tensor(shape=(32, 1, 768), dtype=float32)\n  • value=tf.Tensor(shape=(4, 512, 768), dtype=float32)\n  • key=None\n  • attention_mask=None\n  • return_attention_scores=False\n  • training=None\n  • use_causal_mask=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[129], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx4\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m, tokenizer\u001b[38;5;241m.\u001b[39mdecode(x4[\u001b[38;5;241m2\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n",
      "File \u001b[0;32m~/.conda/envs/esg/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.conda/envs/esg/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:7215\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   7214\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 7215\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Exception encountered when calling layer 'multi_head_attention_1' (type MultiHeadAttention).\n\n{{function_node __wrapped__Einsum_N_2_device_/job:localhost/replica:0/task:0/device:GPU:0}} Expected dimension 4 at axis 0 of the input shaped [32,1,16,48] but got dimension 32 [Op:Einsum]\n\nCall arguments received by layer 'multi_head_attention_1' (type MultiHeadAttention):\n  • query=tf.Tensor(shape=(32, 1, 768), dtype=float32)\n  • value=tf.Tensor(shape=(4, 512, 768), dtype=float32)\n  • key=None\n  • attention_mask=None\n  • return_attention_scores=False\n  • training=None\n  • use_causal_mask=False"
     ]
    }
   ],
   "source": [
    "print(model((x1, x2, x3, x4, prompt)), tokenizer.decode(x4[2], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(4, 1), dtype=int64, numpy=\n",
       " array([[1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1]])>,\n",
       " <tf.Tensor: shape=(4, 512), dtype=int64, numpy=\n",
       " array([[ 2679,  3586,   102, ...,     0,     0,     0],\n",
       "        [ 3137,  2846,   102, ...,     0,     0,     0],\n",
       "        [14211,   102,     0, ...,     0,     0,     0],\n",
       "        [ 2958,   102,     0, ...,     0,     0,     0]])>)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_gen[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>l1</th>\n",
       "      <th>l2</th>\n",
       "      <th>l3</th>\n",
       "      <th>l1_encoded</th>\n",
       "      <th>l2_encoded</th>\n",
       "      <th>l3_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>The Ardee Baroque Festival is a celebration of...</td>\n",
       "      <td>Event</td>\n",
       "      <td>SocietalEvent</td>\n",
       "      <td>MusicFestival</td>\n",
       "      <td>100</td>\n",
       "      <td>251</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>The Slamdance Film Festival is an annual film ...</td>\n",
       "      <td>Event</td>\n",
       "      <td>SocietalEvent</td>\n",
       "      <td>FilmFestival</td>\n",
       "      <td>100</td>\n",
       "      <td>251</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>The Stan Rogers Folk Festival, informally know...</td>\n",
       "      <td>Event</td>\n",
       "      <td>SocietalEvent</td>\n",
       "      <td>MusicFestival</td>\n",
       "      <td>100</td>\n",
       "      <td>251</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1350</th>\n",
       "      <td>The 5th Toronto International Film Festival (T...</td>\n",
       "      <td>Event</td>\n",
       "      <td>SocietalEvent</td>\n",
       "      <td>FilmFestival</td>\n",
       "      <td>100</td>\n",
       "      <td>251</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1886</th>\n",
       "      <td>The 2010 Slamdance Film Festival took place in...</td>\n",
       "      <td>Event</td>\n",
       "      <td>SocietalEvent</td>\n",
       "      <td>FilmFestival</td>\n",
       "      <td>100</td>\n",
       "      <td>251</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240049</th>\n",
       "      <td>The São Paulo International Film Festival (Por...</td>\n",
       "      <td>Event</td>\n",
       "      <td>SocietalEvent</td>\n",
       "      <td>FilmFestival</td>\n",
       "      <td>100</td>\n",
       "      <td>251</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240163</th>\n",
       "      <td>The 40th annual Toronto International Film Fes...</td>\n",
       "      <td>Event</td>\n",
       "      <td>SocietalEvent</td>\n",
       "      <td>FilmFestival</td>\n",
       "      <td>100</td>\n",
       "      <td>251</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240210</th>\n",
       "      <td>During the 19th century Trinidadians and other...</td>\n",
       "      <td>Event</td>\n",
       "      <td>SocietalEvent</td>\n",
       "      <td>MusicFestival</td>\n",
       "      <td>100</td>\n",
       "      <td>251</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240226</th>\n",
       "      <td>New York Polish Film Festival (abbreviated to ...</td>\n",
       "      <td>Event</td>\n",
       "      <td>SocietalEvent</td>\n",
       "      <td>FilmFestival</td>\n",
       "      <td>100</td>\n",
       "      <td>251</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240253</th>\n",
       "      <td>The 40th Venice International Film Festival wa...</td>\n",
       "      <td>Event</td>\n",
       "      <td>SocietalEvent</td>\n",
       "      <td>FilmFestival</td>\n",
       "      <td>100</td>\n",
       "      <td>251</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>881 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text     l1  \\\n",
       "214     The Ardee Baroque Festival is a celebration of...  Event   \n",
       "653     The Slamdance Film Festival is an annual film ...  Event   \n",
       "774     The Stan Rogers Folk Festival, informally know...  Event   \n",
       "1350    The 5th Toronto International Film Festival (T...  Event   \n",
       "1886    The 2010 Slamdance Film Festival took place in...  Event   \n",
       "...                                                   ...    ...   \n",
       "240049  The São Paulo International Film Festival (Por...  Event   \n",
       "240163  The 40th annual Toronto International Film Fes...  Event   \n",
       "240210  During the 19th century Trinidadians and other...  Event   \n",
       "240226  New York Polish Film Festival (abbreviated to ...  Event   \n",
       "240253  The 40th Venice International Film Festival wa...  Event   \n",
       "\n",
       "                   l2             l3  l1_encoded  l2_encoded  l3_encoded  \n",
       "214     SocietalEvent  MusicFestival         100         251         171  \n",
       "653     SocietalEvent   FilmFestival         100         251         105  \n",
       "774     SocietalEvent  MusicFestival         100         251         171  \n",
       "1350    SocietalEvent   FilmFestival         100         251         105  \n",
       "1886    SocietalEvent   FilmFestival         100         251         105  \n",
       "...               ...            ...         ...         ...         ...  \n",
       "240049  SocietalEvent   FilmFestival         100         251         105  \n",
       "240163  SocietalEvent   FilmFestival         100         251         105  \n",
       "240210  SocietalEvent  MusicFestival         100         251         171  \n",
       "240226  SocietalEvent   FilmFestival         100         251         105  \n",
       "240253  SocietalEvent   FilmFestival         100         251         105  \n",
       "\n",
       "[881 rows x 7 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['l3'].str.contains('Festival')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ZZ_VIRTUAL'], dtype=object)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_with_virtual = np.append(topics, 'ZZ_VIRTUAL')\n",
    "le = LabelEncoder()\n",
    "le.fit(topics_with_virtual)\n",
    "le.inverse_transform([298])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_ranking'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[160], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense, Input\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_ranking\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspektral\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GCNConv, GlobalAvgPool, GraphMasking\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# n_out = dataset.n_labels\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_ranking'"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Build model\n",
    "################################################################################\n",
    "from tensorflow import int64\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "import tensorflow_ranking\n",
    "\n",
    "from spektral.layers import GCNConv, GlobalAvgPool, GraphMasking\n",
    "\n",
    "# n_out = dataset.n_labels\n",
    "\n",
    "X_in = Input(shape=(50))\n",
    "A_in = Input(shape=(None,), sparse=True)\n",
    "I_in = Input(shape=(), dtype=int64)\n",
    "\n",
    "X = GCNConv(32, activation='relu')([X_in, A_in])\n",
    "X = GCNConv(32, activation='relu')([X, A_in])\n",
    "X = GlobalAvgPool()([X, I_in])\n",
    "\n",
    "shared_bilinear = tensorflow_ranking.keras.layers.Bilinear(32, 32)\n",
    "X_1 = shared_bilinear([X, X])\n",
    "X = shared_bilinear([X, X], training=False)\n",
    "\n",
    "out = Dense(2, activation='softmax')(X)\n",
    "\n",
    "model = Model(inputs=[X_in, A_in, I_in], outputs=out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "preds = tf.constant([[[-11.7803297],\n",
    " [-9.34260654],\n",
    " [-14.0992193],\n",
    " [-9.90242]],[[-11.7803297],\n",
    " [-9.34260654],\n",
    " [-14.0992193],\n",
    " [-9.90242]]], dtype=float)\n",
    "\n",
    "target = tf.constant([[[0],\n",
    " [0],\n",
    " [0],\n",
    " [1]],[[0],\n",
    " [0],\n",
    " [0],\n",
    " [1]]], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoided = tf.keras.activations.sigmoid(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(labels=tf.reshape(target, shape=(2, -1)), logits=tf.reshape(sigmoided, shape=(2, -1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.activations.softmax(tf.reshape(preds, shape=(1, -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reshape(target, shape=(2, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "4e907c9c662b38b6fe9e69d6881d7a36bc6e4ecfbfed88be2a66ef06ac6f6bc4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
